{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsk/anaconda3/envs/python3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "L_RATE = 0.001\n",
    "EPOCH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_encoder = {\n",
    "    'dog': 0,\n",
    "    'elephant': 1,\n",
    "    'giraffe': 2,\n",
    "    'guitar': 3,\n",
    "    'horse': 4,\n",
    "    'house': 5,\n",
    "    'person': 6\n",
    "}\n",
    "\n",
    "class ArtDataset(Dataset):\n",
    "    def __init__(self, file_list, transforms, mode='train'):\n",
    "        self.file_list = file_list\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            label = 0\n",
    "        else:\n",
    "            label = img_path.split('/')[2]\n",
    "            label = class_encoder[label]\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        img = self.transforms(img)\n",
    "            \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomCrop((224,224)),\n",
    "                                      transforms.RandomGrayscale(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Resize((224,224)),\n",
    "                                      transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((224,224)),\n",
    "                                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './train'\n",
    "img_list = glob(root_dir+'/*/*.jpg')\n",
    "\n",
    "train_list, test_list = train_test_split(img_list, test_size=0.2, shuffle=True, random_state=42)\n",
    "train_set = ArtDataset(train_list, train_transform)\n",
    "test_set = ArtDataset(test_list, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=7)\n",
    "name_list = [name for name, param in model.named_parameters()]\n",
    "for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "    if 'blocks.5' in name:\n",
    "        print(idx)\n",
    "        break\n",
    "print(len(name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EffNet(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(EffNet, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        for (name, param) in list(self.model.named_parameters())[:143]:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) 모델, 손실함수, Optimizer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EffNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= L_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 Train batch 0 loss 3.3141\n",
      "epoch 1 Train batch 10 loss 2.7804\n",
      "epoch 1 Train batch 20 loss 0.4221\n",
      "epoch 1 Train batch 30 loss 0.9344\n",
      "epoch 1 Train batch 40 loss 0.8975\n",
      "epoch 1 Train batch 50 loss 0.4674\n",
      "epoch 1 Train batch 60 loss 1.0677\n",
      "epoch 1 Train batch 70 loss 0.7592\n",
      "epoch 1 Train batch 80 loss 1.3181\n",
      "epoch 1 Validate loss 0.4257 Accuracy: 85.59%\n",
      "epoch 2 Train batch 0 loss 0.2879\n",
      "epoch 2 Train batch 10 loss 0.6150\n",
      "epoch 2 Train batch 20 loss 0.1908\n",
      "epoch 2 Train batch 30 loss 0.0809\n",
      "epoch 2 Train batch 40 loss 0.1267\n",
      "epoch 2 Train batch 50 loss 1.4203\n",
      "epoch 2 Train batch 60 loss 0.2151\n",
      "epoch 2 Train batch 70 loss 0.2238\n",
      "epoch 2 Train batch 80 loss 0.0466\n",
      "epoch 2 Validate loss 0.3537 Accuracy: 89.12%\n",
      "epoch 3 Train batch 0 loss 0.1101\n",
      "epoch 3 Train batch 10 loss 0.0291\n",
      "epoch 3 Train batch 20 loss 0.4081\n",
      "epoch 3 Train batch 30 loss 0.1322\n",
      "epoch 3 Train batch 40 loss 0.3336\n",
      "epoch 3 Train batch 50 loss 0.5837\n",
      "epoch 3 Train batch 60 loss 0.1289\n",
      "epoch 3 Train batch 70 loss 0.1244\n",
      "epoch 3 Train batch 80 loss 0.3513\n",
      "epoch 3 Validate loss 0.4109 Accuracy: 90.29%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    for batch_idx, (img, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(img)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\"epoch {} Train batch {} loss {:.4f}\".format(epoch+1, batch_idx, loss))\n",
    "            \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for img, target in test_loader:\n",
    "            out = model(img)\n",
    "            \n",
    "            loss = criterion(out, target)\n",
    "            test_loss += loss\n",
    "            \n",
    "            pred = torch.max(out, 1)[1]\n",
    "            test_acc += (pred==target).sum().item()\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = test_acc / len(test_set) * 100\n",
    "        \n",
    "    print(\"epoch {} Validate loss {:.4f} Accuracy: {:.2f}%\".format(epoch+1, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './test'\n",
    "test_list = sorted(glob(test_dir+'/0/*.jpg'))\n",
    "TestSet = ArtDataset(test_list, test_transform, mode='test')\n",
    "Test_loader = DataLoader(TestSet, shuffle=False, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "answers=[]\n",
    "\n",
    "for image, _ in Test_loader:\n",
    "    output = model(image)\n",
    "    \n",
    "    pred = np.array(torch.max(output, 1)[1])\n",
    "    for p in pred: answers.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_path = './submission.csv'\n",
    "submission_df = pd.DataFrame({'answer_value': answers})\n",
    "submission_df.to_csv(submission_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
